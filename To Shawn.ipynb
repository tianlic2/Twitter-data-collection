{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df2eb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsidefoods\n",
      "mosa_meat\n",
      "_superMeat_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import time\n",
    "'''抓取tweets：\n",
    "抓取後通過tweet.in_reply_to_status_id == None過濾掉所有reply，最終生成三份csv文件：1）all data， 2）all replies\n",
    "3）data without replies\n",
    "'''\n",
    "\n",
    "#you may need to change the following consumer keys to your own keys, you will see them in your Twitter developer account\n",
    "consumer_key = 'YRWB6yizS63ZJUW2CpEUqS7TN'\n",
    "consumer_secret = 'ZdMYuSvrCPq2qv5yQ01wpE6FgaQJwvytuYuNnkuWdoMLpjO0sg'\n",
    "access_token = '1315688543784562688-UYAqRnekf0mDKoQgsZWoKiBGqlffNw'\n",
    "access_token_secret = 'wvORx0dHxp9uGXXjAjZEJ1hj8eLGcckRlOlmzvxhSqAEA'\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "tweets = []\n",
    "\n",
    "company_twitter_name= ['upsidefoods','mosa_meat','_superMeat_'] # a list of companies' twitter account\n",
    "\n",
    "#this method can collect at most 3,200 most recent posts from each user\n",
    "for company_name in company_twitter_name:\n",
    "    print(company_name)\n",
    "    tweets += api.user_timeline(company_name,count=200,page=1,tweet_mode='extended')\n",
    "    for i in range(2,20):\n",
    "        tweets += api.user_timeline(company_name, count=200, page=i,tweet_mode='extended')\n",
    "    time.sleep(10)\n",
    "\n",
    "tweet_text = []\n",
    "published_date = []\n",
    "Company = []\n",
    "URL = []\n",
    "N_likes = []\n",
    "N_retweet = []\n",
    "\n",
    "tweet_text_reply = []\n",
    "published_date_reply = []\n",
    "Company_reply = []\n",
    "URL_reply = []\n",
    "N_likes_reply = []\n",
    "N_retweet_reply = []\n",
    "\n",
    "\n",
    "tweet_text_RT = []\n",
    "published_date_RT = []\n",
    "Company_RT = []\n",
    "URL_RT = []\n",
    "N_likes_RT = []\n",
    "N_retweet_RT = []\n",
    "\n",
    "\n",
    "tweet_text_alldata = []\n",
    "published_date_alldata = []\n",
    "Company_alldata = []\n",
    "URL_alldata = []\n",
    "N_likes_alldata = []\n",
    "N_retweet_alldata = []\n",
    "Entities_alldata = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    if tweet.in_reply_to_status_id == None:\n",
    "        if hasattr(tweet, 'retweeted_status'):\n",
    "            tweet_text_alldata.append('RT: '+tweet.full_text)\n",
    "        elif hasattr(tweet,'quoted_status'):\n",
    "            tweet_text_alldata.append('QT: '+tweet.quoted_status.full_text)\n",
    "        else:\n",
    "            tweet_text_alldata.append(tweet.full_text)\n",
    "        published_date_alldata.append(tweet.created_at)\n",
    "        Company_alldata.append(tweet.user.name)\n",
    "        N_likes_alldata.append(tweet.favorite_count)\n",
    "        N_retweet_alldata.append(tweet.retweet_count)\n",
    "        Entities_alldata.append(tweet.entities)\n",
    "        URL_alldata.append(f\"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}\")\n",
    "    if tweet.in_reply_to_status_id == None:\n",
    "        if hasattr(tweet, 'retweeted_status'):\n",
    "            tweet_text_RT.append('RT: '+tweet.retweeted_status.full_text)\n",
    "            published_date_RT.append(tweet.created_at)\n",
    "            Company_RT.append(tweet.user.name)\n",
    "            URL_RT.append(f\"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}\")\n",
    "        elif not hasattr(tweet,'quoted_status'):\n",
    "            tweet_text.append(tweet.full_text)\n",
    "            published_date.append(tweet.created_at)\n",
    "            Company.append(tweet.user.name)\n",
    "            URL.append(f\"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}\")\n",
    "    else:\n",
    "        tweet_text_reply.append(tweet.full_text)\n",
    "        published_date_reply.append(tweet.created_at)\n",
    "        Company_reply.append(tweet.user.name)\n",
    "        URL_reply.append(f\"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}\")\n",
    "\n",
    "#all tweets without replies\n",
    "dat = pd.DataFrame(data=[text for text in tweet_text_alldata],columns=['tweets'])\n",
    "dat[\"date\"]=np.array([date for date in published_date_alldata])\n",
    "dat[\"Company\"]=np.array([company for company in Company_alldata])\n",
    "dat['url']=np.array([url for url in URL_alldata])\n",
    "dat['likes'] = np.array([i for i in N_likes_alldata])\n",
    "dat['retweet'] = np.array([i for i in N_retweet_alldata])\n",
    "dat.to_csv('nameofthefile.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
